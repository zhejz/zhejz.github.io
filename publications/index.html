<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Zhejun Zhang | 张喆骏</title> <meta name="author" content="Zhejun Zhang"/> <meta name="description" content="Research Scientist at Huawei Zurich Research Center. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/pepino.JPG"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://zhejz.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Zhejun Zhang | 张喆骏</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/patents/">patents</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="year">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/catk_preview.jpg"></div> <div id="zhang2025closed" class="col-sm-8"> <div class="title">Closed-Loop Supervised Fine-Tuning of Tokenized Traffic Models</div> <div class="author"> <em>Zhejun Zhang</em>, <a href="https://karkus.tilda.ws/" target="_blank" rel="noopener noreferrer">Peter Karkus</a>, <a href="https://maximilianigl.com/" target="_blank" rel="noopener noreferrer">Maximilian Igl</a>, <a href="https://wenhao.pub/" target="_blank" rel="noopener noreferrer">Wenhao Ding</a>, <a href="https://research.nvidia.com/labs/avg/author/yuxiao-chen/" target="_blank" rel="noopener noreferrer">Yuxiao Chen</a>, <a href="https://www.borisivanovic.com/" target="_blank" rel="noopener noreferrer">Boris Ivanovic</a>, and <a href="https://web.stanford.edu/~pavone/index.html" target="_blank" rel="noopener noreferrer">Marco Pavone</a> </div> <div class="periodical"> <em>In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em> 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2412.05334" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/NVlabs/catk" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/catk" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="abstract hidden"> <p>Traffic simulation aims to learn a policy for traffic agents that, when unrolled in closed-loop, faithfully recovers the joint distribution of trajectories observed in the real world. Inspired by large language models, tokenized multi-agent policies have recently become the state-of-the-art in traffic simulation. However, they are typically trained through open-loop behavior cloning, and thus suffer from covariate shift when executed in closed-loop during simulation. In this work, we present Closest Among Top-K (CAT-K) rollouts, a simple yet effective closed-loop fine-tuning strategy to mitigate covariate shift. CAT-K fine-tuning only requires existing trajectory data, without reinforcement learning or generative adversarial imitation. Concretely, CAT-K fine-tuning enables a small 7M-parameter tokenized traffic simulation policy to outperform a 102M-parameter model from the same model family, achieving the top spot on the Waymo Sim Agent Challenge leaderboard at the time of submission.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2025closed</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Closed-Loop Supervised Fine-Tuning of Tokenized Traffic Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Zhejun and Karkus, Peter and Igl, Maximilian and Ding, Wenhao and Chen, Yuxiao and Ivanovic, Boris and Pavone, Marco}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/phd_thesis_preview.png"></div> <div id="zhang2024neural" class="col-sm-8"> <div class="title">Neural Policies for Prosocial Navigation</div> <div class="author"> <em>Zhejun Zhang</em> </div> <div class="periodical"> 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/zhejun_phd_thesis.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.research-collection.ethz.ch/handle/20.500.11850/698889" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">zhang2024neural</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neural Policies for Prosocial Navigation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Zhejun}</span><span class="p">,</span>
  <span class="na">school</span> <span class="p">=</span> <span class="s">{ETH Zurich}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">type</span> <span class="p">=</span> <span class="s">{PhD thesis}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Zurich, Switzerland}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/cvpr2024_winner_preview.jpg"></div> <div id="zhang2024trafficbots" class="col-sm-8"> <div class="title">TrafficBots V1.5: Traffic Simulation via Conditional VAEs and Transformers with Relative Pose Encoding</div> <div class="author"> <em>Zhejun Zhang</em>, <a href="http://people.ee.ethz.ch/~csakarid/" target="_blank" rel="noopener noreferrer">Christos Sakaridis</a>, and <a href="https://insait.ai/prof-luc-van-gool/" target="_blank" rel="noopener noreferrer">Luc Van Gool</a> </div> <div class="periodical"> <em>arXiv preprint arXiv:2406.10898</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2406.10898" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/zhejz/TrafficBotsV1.5" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>In this technical report we present TrafficBots V1.5, a baseline method for the closed-loop simulation of traffic agents. TrafficBots V1.5 achieves baseline-level performance and a 3rd place ranking in the Waymo Open Sim Agents Challenge (WOSAC) 2024. It is a simple baseline that combines TrafficBots, a CVAE-based multi-agent policy conditioned on each agent’s individual destination and personality, and HPTR, the heterogeneous polyline transformer with relative pose encoding. To improve the performance on the WOSAC leaderboard, we apply scheduled teacher-forcing at the training time and we filter the sampled scenarios at the inference time.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2024trafficbots</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{TrafficBots V1.5: Traffic Simulation via Conditional VAEs and Transformers with Relative Pose Encoding}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Zhejun and Sakaridis, Christos and Van Gool, Luc}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2406.10898}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/hptr_preview.png"></div> <div id="zhang2024hptr" class="col-sm-8"> <div class="title">Real-Time Motion Prediction via Heterogeneous Polyline Transformer with Relative Pose Encoding</div> <div class="author"> <em>Zhejun Zhang</em>, <a href="https://alexliniger.github.io/" target="_blank" rel="noopener noreferrer">Alexander Liniger</a>, <a href="http://people.ee.ethz.ch/~csakarid/" target="_blank" rel="noopener noreferrer">Christos Sakaridis</a>, Fisher Yu, and <a href="https://insait.ai/prof-luc-van-gool/" target="_blank" rel="noopener noreferrer">Luc Van Gool</a> </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2310.12970" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/zhejz/HPTR" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/hptr" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="abstract hidden"> <p>The real-world deployment of an autonomous driving system requires its components to run on-board and in real-time, including the motion prediction module that predicts the future trajectories of surrounding traffic participants. Existing agent-centric methods have demonstrated outstanding performance on public benchmarks. However, they suffer from high computational overhead and poor scalability as the number of agents to be predicted increases. To address this problem, we introduce the K-nearest neighbor attention with relative pose encoding (KNARPE), a novel attention mechanism allowing the pairwise-relative representation to be used by Transformers. Then, based on KNARPE we present the heterogeneous polyline Transformer with relative pose encoding (HPTR), a hierarchical framework enabling asynchronous token update during the online inference. By sharing contexts among agents and reusing the unchanged contexts, our approach is as efficient as scene-centric methods, while performing on par with state-of-the-art agent-centric methods. Experiments on Waymo and Argoverse-2 datasets show that HPTR achieves superior performance among end-to-end methods that do not apply expensive post-processing or ensembling.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2024hptr</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Real-Time Motion Prediction via Heterogeneous Polyline Transformer with Relative Pose Encoding}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems (NeurIPS)}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Zhejun and Liniger, Alexander and Sakaridis, Christos and Yu, Fisher and Van Gool, Luc}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/trafficbots_preview.png"></div> <div id="zhang2023trafficbots" class="col-sm-8"> <div class="title">TrafficBots: Towards World Models for Autonomous Driving Simulation and Motion Prediction</div> <div class="author"> <em>Zhejun Zhang</em>, <a href="https://alexliniger.github.io/" target="_blank" rel="noopener noreferrer">Alexander Liniger</a>, <a href="https://scholar.google.ch/citations?user=T51W57YAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Dengxin Dai</a>, Fisher Yu, and <a href="https://insait.ai/prof-luc-van-gool/" target="_blank" rel="noopener noreferrer">Luc Van Gool</a> </div> <div class="periodical"> <em>In International Conference on Robotics and Automation (ICRA)</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2303.04116" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://data.epo.org/gpi/EP4296898A1" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Patent</a> <a href="https://github.com/zhejz/TrafficBots" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/trafficbots" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="abstract hidden"> <p>Data-driven simulation has become a favorable way to train and test autonomous driving algorithms. The idea of replacing the actual environment with a learned simulator has also been explored in model-based reinforcement learning in the context of world models. In this work, we show data-driven traffic simulation can be formulated as a world model. We present TrafficBots, a multi-agent policy built upon motion prediction and end-to-end driving, and based on TrafficBots we obtain a world model tailored for the planning module of autonomous vehicles. Existing data-driven traffic simulators are lacking configurability and scalability. To generate configurable behaviors, for each agent we introduce a destination as navigational information, and a time-invariant latent personality that specifies the behavioral style. To improve the scalability, we present a new scheme of positional encoding for angles, allowing all agents to share the same vectorized context and the use of an architecture based on dot-product attention. As a result, we can simulate all traffic participants seen in dense urban scenarios. Experiments on the Waymo open motion dataset show TrafficBots can simulate realistic multi-agent behaviors and achieve good performance on the motion prediction task.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2023trafficbots</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{TrafficBots: Towards World Models for Autonomous Driving Simulation and Motion Prediction}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Robotics and Automation (ICRA)}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Zhejun and Liniger, Alexander and Dai, Dengxin and Yu, Fisher and Van Gool, Luc}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">patent</span> <span class="p">=</span> <span class="s">{https://data.epo.org/gpi/EP4296898A1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/saferl_preview.png"></div> <div id="buehrer2023multiplicative" class="col-sm-8"> <div class="title">A Multiplicative Value Function for Safe and Efficient Reinforcement Learning</div> <div class="author"> <a href="https://www.linkedin.com/in/nick-b%C3%BChrer/" target="_blank" rel="noopener noreferrer">Nick Bührer</a>, <em>Zhejun Zhang</em>, <a href="https://alexliniger.github.io/" target="_blank" rel="noopener noreferrer">Alexander Liniger</a>, Fisher Yu, and <a href="https://insait.ai/prof-luc-van-gool/" target="_blank" rel="noopener noreferrer">Luc Van Gool</a> </div> <div class="periodical"> <em>In International Conference on Intelligent Robots and Systems (IROS)</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2303.04118" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/nikeke19/Safe-Mult-RL" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/saferl" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="abstract hidden"> <p>An emerging field of sequential decision problems is safe Reinforcement Learning (RL), where the objective is to maximize the reward while obeying safety constraints. Being able to handle constraints is essential for deploying RL agents in real-world environments, where constraint violations can harm the agent and the environment. To this end, we propose a safe model-free RL algorithm with a novel multiplicative value function consisting of a safety critic and a reward critic. The safety critic predicts the probability of constraint violation and discounts the reward critic that only estimates constraint-free returns. By splitting responsibilities, we facilitate the learning task leading to increased sample efficiency. We integrate our approach into two popular RL algorithms, Proximal Policy Optimization and Soft Actor-Critic, and evaluate our method in four safety-focused environments, including classical RL benchmarks augmented with safety constraints and robot navigation tasks with images and raw Lidar scans as observations. Finally, we make the zero-shot sim-to-real transfer where a differential drive robot has to navigate through a cluttered room.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">buehrer2023multiplicative</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Multiplicative Value Function for Safe and Efficient Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Intelligent Robots and Systems (IROS)}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{B{\"u}hrer, Nick and Zhang, Zhejun and Liniger, Alexander and Yu, Fisher and Van Gool, Luc}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/roach_preview.png"></div> <div id="zhang2021roach" class="col-sm-8"> <div class="title">End-to-End Urban Driving by Imitating a Reinforcement Learning Coach</div> <div class="author"> <em>Zhejun Zhang</em>, <a href="https://alexliniger.github.io/" target="_blank" rel="noopener noreferrer">Alexander Liniger</a>, <a href="https://scholar.google.ch/citations?user=T51W57YAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Dengxin Dai</a>, Fisher Yu, and <a href="https://insait.ai/prof-luc-van-gool/" target="_blank" rel="noopener noreferrer">Luc Van Gool</a> </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2108.08265" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://data.epo.org/gpi/EP4124995A1" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Patent</a> <a href="https://github.com/zhejz/carla-roach" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/roach" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="abstract hidden"> <p>End-to-end approaches to autonomous driving commonly rely on expert demonstrations. Although humans are good drivers, they are not good coaches for end-to-end algorithms that demand dense on-policy supervision. On the contrary, automated experts that leverage privileged information can efficiently generate large scale on-policy and off-policy demonstrations. However, existing automated experts for urban driving make heavy use of hand-crafted rules and perform suboptimally even on driving simulators, where ground-truth information is available. To address these issues, we train a reinforcement learning expert that maps bird’s-eye view images to continuous low-level actions. While setting a new performance upper-bound on CARLA, our expert is also a better coach that provides informative supervision signals for imitation learning agents to learn from. Supervised by our reinforcement learning coach, a baseline end-to-end agent with monocular camera-input achieves expert-level performance. Our end-to-end agent achieves a 78% success rate while generalizing to a new town and new weather on the NoCrash-dense benchmark and state-of-the-art performance on the challenging public routes of the CARLA LeaderBoard.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2021roach</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{End-to-End Urban Driving by Imitating a Reinforcement Learning Coach}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Zhejun and Liniger, Alexander and Dai, Dengxin and Yu, Fisher and Van Gool, Luc}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">patent</span> <span class="p">=</span> <span class="s">{https://data.epo.org/gpi/EP4124995A1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2025 Zhejun Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>